{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fszta/Digit-recognition/blob/master/train_gpu_google_co.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cbxH8H14kyAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c67792e5-239e-4c24-f36a-01df1a4e9f2a"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Fszta/Digit-recognition.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Digit-recognition'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 37 (delta 9), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jQCZUUjflALv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1329
        },
        "outputId": "1cf3bb8d-2c15-4993-f465-7031766eebc7"
      },
      "cell_type": "code",
      "source": [
        "!cd Digit-recognition/\n",
        "!pip install -r Digit-recognition/requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting h5py==2.9.0 (from -r Digit-recognition/requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.8MB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from -r Digit-recognition/requirements.txt (line 3)) (2.2.4)\n",
            "Requirement already satisfied: kiwisolver==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r Digit-recognition/requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: matplotlib==3.0.2 in /usr/local/lib/python3.6/dist-packages (from -r Digit-recognition/requirements.txt (line 6)) (3.0.2)\n",
            "Collecting numpy==1.15.4 (from -r Digit-recognition/requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 3.0MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.0.0.21 (from -r Digit-recognition/requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/49/874d119948a5a084a7ebe98308214098ef3471d76ab74200f9800efeef15/opencv_python-4.0.0.21-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 25.4MB 1.2MB/s \n",
            "\u001b[?25hCollecting pandas==0.23.4 (from -r Digit-recognition/requirements.txt (line 10))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/d8/feeb346d41f181e83fba45224ab14a8d8af019b48af742e047f3845d8cff/pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 8.9MB 5.7MB/s \n",
            "\u001b[?25hCollecting Pillow==5.4.1 (from -r Digit-recognition/requirements.txt (line 12))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==0.20.2 in /usr/local/lib/python3.6/dist-packages (from -r Digit-recognition/requirements.txt (line 14)) (0.20.2)\n",
            "Collecting scipy==1.2.0 (from -r Digit-recognition/requirements.txt (line 15))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/e6/6d4edaceee6a110ecf6f318482f5229792f143e468b34a631f5a0899f56d/scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 26.6MB 1.7MB/s \n",
            "\u001b[?25hCollecting seaborn==0.9.0 (from -r Digit-recognition/requirements.txt (line 16))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
            "\u001b[K    100% |████████████████████████████████| 215kB 26.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.6/dist-packages (from -r Digit-recognition/requirements.txt (line 18)) (0.0)\n",
            "Requirement already satisfied: tensorflow==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r Digit-recognition/requirements.txt (line 19)) (1.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.9.0->-r Digit-recognition/requirements.txt (line 2)) (1.11.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r Digit-recognition/requirements.txt (line 3)) (1.0.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r Digit-recognition/requirements.txt (line 3)) (1.0.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.4->-r Digit-recognition/requirements.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver==1.0.1->-r Digit-recognition/requirements.txt (line 4)) (40.6.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2->-r Digit-recognition/requirements.txt (line 6)) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2->-r Digit-recognition/requirements.txt (line 6)) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.2->-r Digit-recognition/requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4->-r Digit-recognition/requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (1.12.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (3.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (0.32.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r Digit-recognition/requirements.txt (line 19)) (3.0.1)\n",
            "\u001b[31myellowbrick 0.9 has requirement matplotlib<3.0,>=1.5.1, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, h5py, opencv-python, pandas, Pillow, scipy, seaborn\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: h5py 2.8.0\n",
            "    Uninstalling h5py-2.8.0:\n",
            "      Successfully uninstalled h5py-2.8.0\n",
            "  Found existing installation: opencv-python 3.4.5.20\n",
            "    Uninstalling opencv-python-3.4.5.20:\n",
            "      Successfully uninstalled opencv-python-3.4.5.20\n",
            "  Found existing installation: pandas 0.22.0\n",
            "    Uninstalling pandas-0.22.0:\n",
            "      Successfully uninstalled pandas-0.22.0\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "  Found existing installation: scipy 1.1.0\n",
            "    Uninstalling scipy-1.1.0:\n",
            "      Successfully uninstalled scipy-1.1.0\n",
            "  Found existing installation: seaborn 0.7.1\n",
            "    Uninstalling seaborn-0.7.1:\n",
            "      Successfully uninstalled seaborn-0.7.1\n",
            "Successfully installed Pillow-5.4.1 h5py-2.9.0 numpy-1.15.4 opencv-python-4.0.0.21 pandas-0.23.4 scipy-1.2.0 seaborn-0.9.0\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [PIL, numpy, pandas, scipy, seaborn]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "begGKiBolEtt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ba3585c-1760-4e6f-815a-652b4cb1b6ad"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6MA3dcDumk0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "53fdf47f-092c-4f7a-d689-22889d3f2e8c"
      },
      "cell_type": "code",
      "source": [
        "# Set dimension ordering convention \n",
        "K.set_image_dim_ordering('th')\n",
        "seed = 5\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Training set description\n",
        "sns.set(style=\"darkgrid\")\n",
        "sns.countplot(y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  cat_pos = np.ones(swarm_data.size) * center\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24b9e25748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFLCAYAAAA6dp6kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAM9P8AE/iDp4YPJlgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PLj5EtzzmtBq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reshape as (channel, width, height)\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
        "\n",
        "# Inputs normalizations\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p9w969MOmvnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c7e54188-f6fd-4f6c-e01b-052740ca6601"
      },
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "plt.imshow(X_train[0][0,:,:], cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f24b70e97f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8H/LFmKD6IYI7AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "s1JoKksOm8yQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "juzj9f1nnBgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2618
        },
        "outputId": "cdb59e1c-f2e4-448c-a76e-f08d6add3131"
      },
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=200)\n",
        "\n",
        "# Evaluate the model \n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n",
        "model.save('model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0186 - acc: 0.9934 - val_loss: 0.0354 - val_acc: 0.9902\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0280 - val_acc: 0.9924\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0170 - acc: 0.9939 - val_loss: 0.0283 - val_acc: 0.9919\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0173 - acc: 0.9942 - val_loss: 0.0240 - val_acc: 0.9927\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0270 - val_acc: 0.9930\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0156 - acc: 0.9948 - val_loss: 0.0265 - val_acc: 0.9928\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0155 - acc: 0.9944 - val_loss: 0.0289 - val_acc: 0.9920\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0124 - acc: 0.9955 - val_loss: 0.0258 - val_acc: 0.9930\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0135 - acc: 0.9953 - val_loss: 0.0289 - val_acc: 0.9922\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0125 - acc: 0.9955 - val_loss: 0.0308 - val_acc: 0.9918\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0136 - acc: 0.9954 - val_loss: 0.0284 - val_acc: 0.9928\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0129 - acc: 0.9955 - val_loss: 0.0291 - val_acc: 0.9926\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0277 - val_acc: 0.9917\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0131 - acc: 0.9953 - val_loss: 0.0271 - val_acc: 0.9926\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0231 - val_acc: 0.9926\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0264 - val_acc: 0.9932\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0112 - acc: 0.9960 - val_loss: 0.0270 - val_acc: 0.9935\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0112 - acc: 0.9961 - val_loss: 0.0288 - val_acc: 0.9926\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0095 - acc: 0.9970 - val_loss: 0.0268 - val_acc: 0.9935\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0111 - acc: 0.9965 - val_loss: 0.0281 - val_acc: 0.9933\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0255 - val_acc: 0.9933\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0091 - acc: 0.9968 - val_loss: 0.0287 - val_acc: 0.9927\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.0289 - val_acc: 0.9923\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0334 - val_acc: 0.9922\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0312 - val_acc: 0.9923\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0289 - val_acc: 0.9939\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0324 - val_acc: 0.9920\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.0295 - val_acc: 0.9924\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0308 - val_acc: 0.9932\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0277 - val_acc: 0.9934\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0329 - val_acc: 0.9921\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0291 - val_acc: 0.9939\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0283 - val_acc: 0.9935\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0088 - acc: 0.9969 - val_loss: 0.0304 - val_acc: 0.9938\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0303 - val_acc: 0.9924\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0307 - val_acc: 0.9938\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.0279 - val_acc: 0.9938\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0288 - val_acc: 0.9925\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0281 - val_acc: 0.9926\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0066 - acc: 0.9977 - val_loss: 0.0322 - val_acc: 0.9926\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0319 - val_acc: 0.9928\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0320 - val_acc: 0.9920\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0330 - val_acc: 0.9919\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0297 - val_acc: 0.9932\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0295 - val_acc: 0.9934\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0274 - val_acc: 0.9931\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0066 - acc: 0.9977 - val_loss: 0.0294 - val_acc: 0.9925\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0305 - val_acc: 0.9940\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0297 - val_acc: 0.9923\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0058 - acc: 0.9978 - val_loss: 0.0304 - val_acc: 0.9928\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.0294 - val_acc: 0.9932\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0074 - acc: 0.9975 - val_loss: 0.0295 - val_acc: 0.9935\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0073 - acc: 0.9975 - val_loss: 0.0264 - val_acc: 0.9936\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0279 - val_acc: 0.9933\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0264 - val_acc: 0.9929\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0313 - val_acc: 0.9927\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0274 - val_acc: 0.9932\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0321 - val_acc: 0.9924\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0270 - val_acc: 0.9937\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0056 - acc: 0.9980 - val_loss: 0.0292 - val_acc: 0.9933\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0288 - val_acc: 0.9927\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0280 - val_acc: 0.9928\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0299 - val_acc: 0.9934\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0273 - val_acc: 0.9939\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0266 - val_acc: 0.9936\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0276 - val_acc: 0.9938\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0271 - val_acc: 0.9940\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0293 - val_acc: 0.9943\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0323 - val_acc: 0.9933\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0323 - val_acc: 0.9921\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0299 - val_acc: 0.9936\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0311 - val_acc: 0.9924\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0245 - val_acc: 0.9934\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0277 - val_acc: 0.9928\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0312 - val_acc: 0.9934\n",
            "Epoch 76/100\n",
            "34800/60000 [================>.............] - ETA: 1s - loss: 0.0037 - acc: 0.9986"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}